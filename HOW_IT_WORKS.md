# How It Works: Technical System Architecture

## Complete Workflow: PRD Update to Production Deployment

### Phase 1: Human Defines Requirements

#### Step 1.1: Update Product Files

Developer updates files in `product/` folder:

```bash
product/
â”œâ”€â”€ prd.md                    # Add feature requirements
â”œâ”€â”€ user_flows.md             # Document user journey
â”œâ”€â”€ ui_kit.md                 # Define visual design
â”œâ”€â”€ performance_budget.md     # Set performance targets
â”œâ”€â”€ seo_requirements.md       # SEO requirements
â””â”€â”€ constraints.md            # Technical constraints
```

**Example PRD Update**:
```markdown
## Feature: Real-Time Dashboard

### Priority: P0

### User Story
As a product manager, I want to see real-time metrics
so that I can make data-driven decisions instantly.

### Acceptance Criteria
- Dashboard loads in <2 seconds
- Updates appear within 500ms of data change
- Works on mobile and desktop
- SEO: Dashboard is private (no indexing needed)

### Performance Requirements
- Lighthouse score >90
- Core Web Vitals: LCP <2s, FID <100ms, CLS <0.1
- Real-time updates: <500ms latency

### Accessibility
- WCAG 2.1 AA compliance
- Keyboard navigation complete
- Screen reader compatible
```

#### Step 1.2: Commit Changes

```bash
git commit -m "feat(product): add real-time dashboard feature"
git push origin feature/dashboard
```

### Phase 2: Validation Hooks Fire

#### Hook 1: user_prompt_submit.py

**When**: Immediately when developer submits prompt to Claude Code

**Validates**:
```python
# Pseudo-code
def validate_prompt():
    # 1. Check PRD has been updated
    if not prd_updated():
        raise ValidationError("Update product/prd.md first")
    
    # 2. Scan for secrets (API keys, tokens)
    if contains_secrets(prompt):
        raise SecurityError("Remove secrets from prompt")
    
    # 3. Inject context
    context = {
        "current_bundle_size": "182KB",
        "latest_lighthouse_score": 92,
        "recent_commits": get_last_commits(5),
        "performance_budget": get_budget("dashboard"),
        "seo_requirements": get_seo_requirements("dashboard"),
    }
    
    # 4. Generate session
    session = create_session(prompt, context)
    
    return session
```

**Blocking Conditions**:
- âŒ Secrets detected in prompt
- âŒ PRD not updated
- âŒ Performance budget not defined for new pages
- âŒ SEO requirements missing for new pages

#### Hook 2: prd_validator.py

**When**: Triggered by user_prompt_submit.py

**Validates PRD Completeness**:
```python
# Pseudo-code
def validate_prd():
    prd = load_prd()
    
    # Check required sections
    required_sections = [
        "executive_summary",
        "problem_statement",
        "target_audience",
        "success_metrics",
        "core_features",
        "user_flows",
        "design_system",
        "constraints",
        "non_goals",
        "seo_requirements",
        "performance_budget",
    ]
    
    for section in required_sections:
        if not prd.has_section(section):
            raise ValidationError(f"Missing required section: {section}")
    
    # Validate each feature has required attributes
    for feature in prd.features:
        assert feature.acceptance_criteria, "Feature needs acceptance criteria"
        assert feature.performance_requirements, "Feature needs performance targets"
        assert feature.accessibility_requirements, "Feature needs a11y spec"
    
    # Cross-reference validation
    for page in prd.pages:
        assert prd.has_seo_requirements(page), f"Missing SEO requirements for {page}"
        assert prd.has_performance_budget(page), f"Missing performance budget for {page}"
    
    return True
```

**Output**:
- âœ… PRD validation report
- âŒ Missing items list
- ðŸ’¡ Recommendations

### Phase 3: Developer Submits to Claude Code

Developer opens Claude Code and submits:

```
"Implement the real-time dashboard feature from the PRD.
Use WebSockets for real-time updates, ensure SEO compliance,
and maintain 90+ Lighthouse score."
```

### Phase 4: Orchestrator Analyzes and Plans

#### Orchestrator Logic

```python
# Pseudo-code
class Orchestrator:
    def create_plan(self, prompt, context):
        # 1. Parse requirements
        requirements = parse_prompt(prompt)
        prd = load_prd()
        
        # 2. Identify work items
        tasks = {
            "frontend": [
                Task(name="Dashboard page component",
                     priority=P0, complexity=high),
                Task(name="Real-time metrics widget",
                     priority=P0, complexity=medium),
                Task(name="WebSocket client",
                     priority=P0, complexity=high),
            ],
            "backend": [
                Task(name="Metrics aggregation API",
                     priority=P0, complexity=high),
                Task(name="WebSocket server",
                     priority=P0, complexity=high),
                Task(name="Database optimization",
                     priority=P0, complexity=medium),
            ],
            "infra": [
                Task(name="WebSocket load balancing",
                     priority=P1, complexity=high),
                Task(name="Monitoring for real-time",
                     priority=P1, complexity=medium),
            ],
            "security": [
                Task(name="WebSocket authentication",
                     priority=P0, complexity=medium),
                Task(name="Rate limiting for metrics API",
                     priority=P0, complexity=medium),
            ],
            "testing": [
                Task(name="E2E test for dashboard flow",
                     priority=P0, complexity=medium),
                Task(name="Load test WebSocket",
                     priority=P1, complexity=high),
            ],
        }
        
        # 3. Create execution plan
        plan = ExecutionPlan(
            tasks=tasks,
            parallelization={
                "frontend": ["backend", "infra"],  # Frontend waits for backend contract
                "backend": [],                     # Backend can start immediately
                "infra": ["backend"],              # Infra waits for backend requirements
                "security": [],                    # Security reviews in parallel
                "testing": ["backend"],            # Testing waits for backend
            },
            dependencies={
                "OpenAPI contract": ["backend â†’ frontend"],
                "Database schema": ["backend â†’ infra optimization"],
                "Authentication": ["backend â†’ frontend WebSocket"],
            }
        )
        
        return plan
```

**Execution Plan Output**:

```markdown
# Execution Plan: Real-Time Dashboard

## Parallel Task Delegation

### 1. Backend Engineer (Start immediately)
- [ ] Create `/api/metrics` endpoints
- [ ] Implement WebSocket server
- [ ] Database query optimization
- [ ] Authentication for WebSocket

**Estimated time**: 45 minutes

### 2. Frontend Engineer (Wait for OpenAPI contract)
- [ ] Dashboard page component
- [ ] Real-time metrics widget
- [ ] WebSocket client
- [ ] SEO metadata

**Estimated time**: 40 minutes
**Blocker**: OpenAPI contract from Backend

### 3. Infra Guardian (Wait for backend requirements)
- [ ] WebSocket load balancing
- [ ] Monitoring and alerting
- [ ] Auto-scaling for real-time

**Estimated time**: 30 minutes
**Blocker**: Backend WebSocket details

### 4. Security Reviewer (Parallel to others)
- [ ] Review WebSocket authentication
- [ ] Validate rate limiting
- [ ] Check for common vulnerabilities

**Estimated time**: 20 minutes

### 5. Test Engineer (Wait for backend)
- [ ] E2E test: Dashboard real-time updates
- [ ] Load test: WebSocket connections
- [ ] Performance test: Lighthouse

**Estimated time**: 30 minutes
**Blocker**: Backend implementation

## Total Estimated Time: 45 minutes (vs. 2-4 hours manual)

## Quality Gates Applied

1. **Pre-Tool Use**: Block dangerous operations
2. **Post-Tool Use**: Validate after each change
3. **Web Performance Guard**: Enforce Lighthouse >90
4. **Web Security Scanner**: Check for vulnerabilities
5. **SEO Validator**: Ensure private pages not indexed
6. **Accessibility Validator**: Check WCAG compliance
7. **Test Enforcer**: Ensure 80%+ coverage
8. **Lighthouse CI**: Continuous monitoring
9. **Stop Validator**: Final quality check
```

### Phase 5: Parallel Agent Execution

#### Agent 1: Backend Engineer (Starts immediately)

```typescript
// Pseudo-code: What Backend Engineer creates

// 1. OpenAPI Contract (contracts/metrics.openapi.yaml)
paths:
  /api/metrics:
    get:
      summary: Get current metrics
      parameters:
        - name: dashboard
          in: query
          required: true
      responses:
        200:
          description: Metrics data
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Metrics'
  
  /api/metrics/subscribe:
    post:
      summary: WebSocket connection for real-time updates
      security:
        - bearerAuth: []

// 2. Backend Implementation (api/metrics.controller.ts)
@Controller('/api/metrics')
export class MetricsController {
  constructor(private metricsService: MetricsService) {}
  
  @Get()
  @UseGuards(AuthGuard, RateLimitGuard)
  async getMetrics(@Query('dashboard') dashboardId: string) {
    const metrics = await this.metricsService.getMetrics(dashboardId);
    return MetricsSerializer.serialize(metrics);
  }
  
  @WebSocketGateway('/api/metrics/subscribe')
  @UseGuards(WebSocketAuthGuard)
  handleConnection(client: Socket) {
    // Implement real-time updates
    const interval = setInterval(() => {
      const metrics = this.metricsService.getLatestMetrics();
      client.emit('metrics-update', metrics);
    }, 500);
  }
}

// 3. Database Query Optimization (persistence/metrics.repository.ts)
export class MetricsRepository {
  async getMetrics(dashboardId: string) {
    return this.db.query(
      `SELECT * FROM metrics 
       WHERE dashboard_id = $1 AND created_at > NOW() - INTERVAL '24 hours'
       ORDER BY created_at DESC LIMIT 100`,
      [dashboardId]
    ).index('metrics_dashboard_created');
  }
}

// 4. Business Logic (domain/metrics.service.ts)
export class MetricsService {
  async getMetrics(dashboardId: string): Promise<Metrics> {
    // Business logic for aggregation, filtering, calculation
  }
}

// 5. Tests (tests/integration/metrics.test.ts)
describe('Metrics API', () => {
  it('should return metrics for dashboard', async () => {
    const res = await request(app)
      .get('/api/metrics?dashboard=123')
      .set('Authorization', 'Bearer token');
    
    expect(res.status).toBe(200);
    expect(res.body.metrics).toBeDefined();
  });
  
  it('should reject unauthenticated requests', async () => {
    const res = await request(app)
      .get('/api/metrics?dashboard=123');
    
    expect(res.status).toBe(401);
  });
  
  it('should rate limit excessive requests', async () => {
    // Make 100+ requests in rapid succession
    for (let i = 0; i < 101; i++) {
      const res = await request(app)
        .get('/api/metrics?dashboard=123')
        .set('Authorization', 'Bearer token');
      
      if (i < 100) expect(res.status).toBe(200);
      else expect(res.status).toBe(429); // Too Many Requests
    }
  });
});
```

**Quality Validation After Backend Changes**:

pre_tool_use hooks block:
- âŒ Hardcoded secrets
- âŒ SQL without parameterization
- âŒ Unauthenticated endpoints
- âŒ Missing rate limiting

post_tool_use hooks trigger:
- âœ… TypeScript compilation
- âœ… ESLint validation
- âœ… Unit tests execution
- âœ… API contract validation

#### Agent 2: Frontend Engineer (After OpenAPI contract available)

```typescript
// Pseudo-code: What Frontend Engineer creates

// 1. Dashboard Page Component (src/app/dashboard/page.tsx)
import { generateMetadata } from 'next';

export const generateMetadata = (): Metadata => ({
  title: 'Dashboard - Real-time Metrics',
  description: 'Private dashboard with real-time metrics',
  robots: { index: false, follow: false }, // Not indexed
});

export default function DashboardPage() {
  return (
    <Layout>
      <Dashboard />
    </Layout>
  );
}

// 2. Dashboard Component (src/features/dashboard/Dashboard.tsx)
import { useMetricsWebSocket } from '../hooks/useMetricsWebSocket';
import { MetricsWidget } from '../components/MetricsWidget';

export const Dashboard = () => {
  const { metrics, isConnected } = useMetricsWebSocket('/api/metrics/subscribe');
  
  return (
    <div className="dashboard" role="main" aria-label="Real-time Dashboard">
      <h1>Dashboard</h1>
      <div className="metrics-grid">
        {metrics.map(metric => (
          <MetricsWidget key={metric.id} metric={metric} />
        ))}
      </div>
      <ConnectionStatus isConnected={isConnected} />
    </div>
  );
};

// 3. WebSocket Hook (src/features/dashboard/hooks/useMetricsWebSocket.ts)
export function useMetricsWebSocket(url: string) {
  const [metrics, setMetrics] = useState<Metric[]>([]);
  const [isConnected, setIsConnected] = useState(false);
  
  useEffect(() => {
    const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
    const ws = new WebSocket(`${protocol}//${window.location.host}${url}`);
    
    ws.onopen = () => setIsConnected(true);
    ws.onclose = () => setIsConnected(false);
    ws.onerror = (error) => console.error('WebSocket error:', error);
    
    ws.onmessage = (event) => {
      const data = JSON.parse(event.data);
      setMetrics(data.metrics);
    };
    
    return () => ws.close();
  }, [url]);
  
  return { metrics, isConnected };
}

// 4. Metrics Widget Component (src/features/dashboard/components/MetricsWidget.tsx)
interface MetricsWidgetProps {
  metric: Metric;
}

export const MetricsWidget: React.FC<MetricsWidgetProps> = ({ metric }) => {
  return (
    <article className="metric-card" role="region" aria-label={metric.name}>
      <h2>{metric.name}</h2>
      <div className="metric-value" aria-live="polite" aria-atomic="true">
        {metric.value}
      </div>
      <div className="metric-change" aria-label={`Change: ${metric.change}%`}>
        {metric.change > 0 ? 'ðŸ“ˆ' : 'ðŸ“‰'} {metric.change}%
      </div>
    </article>
  );
};

// 5. Tests (tests/integration/dashboard.test.tsx)
describe('Dashboard', () => {
  it('should render dashboard with metrics', async () => {
    const { getByRole } = render(<Dashboard />);
    expect(getByRole('main')).toBeInTheDocument();
  });
  
  it('should receive real-time updates', async () => {
    const { getByText } = render(<Dashboard />);
    // WebSocket message received
    fireEvent.message(window, {
      data: JSON.stringify({
        metrics: [{ id: 1, name: 'Users', value: 1234, change: 5 }]
      })
    });
    expect(getByText('1234')).toBeInTheDocument();
  });
});
```

**Quality Validation After Frontend Changes**:

web_security_scanner hooks check:
- âœ… No hardcoded API keys
- âœ… Proper WebSocket authentication
- âœ… Input sanitization for metrics display
- âœ… XSS prevention

web_performance_guard hooks check:
- âœ… Bundle size impact (<250KB)
- âœ… Lighthouse score >90
- âœ… Core Web Vitals met

accessibility_validator hooks check:
- âœ… ARIA labels present
- âœ… Semantic HTML used
- âœ… Keyboard navigation works
- âœ… Screen reader compatible

seo_validator hooks check:
- âœ… Meta tags present
- âœ… robots: { index: false } set (private page)
- âœ… No duplicate content

#### Agent 3: Infrastructure Guardian (After backend requirements)

```hcl
# Pseudo-code: What Infrastructure Guardian creates

# 1. Terraform WebSocket Load Balancer (infra/terraform/modules/websocket_lb.tf)
resource "aws_lb" "websocket" {
  name               = "dashboard-websocket-lb"
  internal           = false
  load_balancer_type = "application"
  
  enable_deletion_protection = false
  
  tags = {
    Name = "dashboard-websocket"
  }
}

resource "aws_lb_target_group" "websocket" {
  name        = "dashboard-websocket-tg"
  port        = 3001
  protocol    = "HTTP"
  vpc_id      = var.vpc_id
  
  stickiness {
    type            = "lb_cookie"
    cookie_duration = 86400
    enabled         = true  # Essential for WebSocket
  }
  
  health_check {
    healthy_threshold   = 2
    unhealthy_threshold = 2
    timeout             = 3
    interval            = 30
    path                = "/health"
    matcher             = "200"
  }
}

# 2. Auto-Scaling Configuration (infra/terraform/modules/websocket_scaling.tf)
resource "aws_autoscaling_group" "websocket" {
  name                = "dashboard-websocket-asg"
  vpc_zone_identifier = var.private_subnet_ids
  target_group_arns   = [aws_lb_target_group.websocket.arn]
  health_check_type   = "ELB"
  
  min_size         = 2
  max_size         = 10
  desired_capacity = 3
  
  tag {
    key                 = "Name"
    value               = "dashboard-websocket"
    propagate_at_launch = true
  }
}

resource "aws_autoscaling_policy" "websocket_scale_up" {
  name                   = "dashboard-websocket-scale-up"
  scaling_adjustment     = 1
  adjustment_type        = "ChangeInCapacity"
  cooldown               = 60
  autoscaling_group_name = aws_autoscaling_group.websocket.name
}

resource "aws_cloudwatch_metric_alarm" "websocket_cpu" {
  alarm_name          = "dashboard-websocket-cpu"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = "2"
  metric_name         = "CPUUtilization"
  namespace           = "AWS/EC2"
  period              = "300"
  statistic           = "Average"
  threshold           = "70"
  alarm_actions       = [aws_autoscaling_policy.websocket_scale_up.arn]
}

# 3. Monitoring Dashboard (infra/terraform/modules/monitoring.tf)
resource "aws_cloudwatch_dashboard" "websocket" {
  dashboard_name = "dashboard-websocket"
  dashboard_body = jsonencode({
    widgets = [
      {
        type = "metric"
        properties = {
          metrics = [
            ["AWS/ApplicationELB", "ActiveConnectionCount"],
            ["AWS/ApplicationELB", "NewConnectionCount"],
            ["AWS/EC2", "CPUUtilization"]
          ]
          period = 300
          stat   = "Average"
          region = var.aws_region
          title  = "WebSocket Health"
        }
      }
    ]
  })
}

# 4. Docker Compose for Local Testing (infra/docker/docker-compose.yml)
version: '3.8'

services:
  backend:
    build:
      context: ../../backend
      dockerfile: ../infra/docker/backend.Dockerfile
    ports:
      - "3001:3001"
    environment:
      DATABASE_URL: "postgresql://user:pass@postgres:5432/dashboard"
      JWT_SECRET: "dev-secret"
    depends_on:
      - postgres

  postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: pass
      POSTGRES_DB: dashboard
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

volumes:
  postgres_data:
```

#### Agent 4: Security Reviewer (Parallel to others)

```markdown
# Security Review: Real-Time Dashboard

## Authentication & Authorization
âœ… **WebSocket Authentication**
- Token validated on connection
- Tokens refreshed automatically
- Expired tokens disconnect gracefully

âœ… **Dashboard Authorization**
- Users can only access own dashboard
- Resource ownership verified on backend

## Input Validation
âœ… **API Inputs**
- Dashboard ID validated and sanitized
- Query parameters type-checked
- No SQL injection vectors

## Rate Limiting
âœ… **API Rate Limiting**
- 100 requests/minute per user
- WebSocket messages rate limited
- Prevents DoS attacks

## Security Headers
âœ… **HTTP Headers**
- CSP: script-src 'self'
- X-Frame-Options: DENY
- X-Content-Type-Options: nosniff
- Strict-Transport-Security enabled

## Data Security
âœ… **WebSocket Data**
- All WebSocket messages encrypted (WSS)
- Sensitive data not logged
- No PII in metrics

## Dependency Security
âœ… **npm audit**
- No critical vulnerabilities
- High: 0, Medium: 0
- Dependencies up-to-date

## Vulnerability Scan
âœ… **OWASP Top 10**
- A01:2021 Broken Access Control: âœ… Passed
- A02:2021 Cryptographic Failures: âœ… Passed
- A03:2021 Injection: âœ… Passed
- A07:2021 XSS: âœ… Passed
- A09:2021 SSRF: âœ… Passed

## Recommendations
- Consider rate limiting WebSocket connections per IP
- Add request signing for sensitive metrics

## Status: âœ… APPROVED
```

#### Agent 5: Test Engineer (After backend implementation)

```typescript
// E2E Tests (tests/e2e/dashboard.spec.ts)
import { test, expect } from '@playwright/test';

test('dashboard real-time updates', async ({ page, context }) => {
  // 1. Login
  await page.goto('http://localhost:3000/login');
  await page.fill('input[name="email"]', 'test@example.com');
  await page.fill('input[name="password"]', 'password123');
  await page.click('button:has-text("Login")');
  
  // 2. Navigate to dashboard
  await page.goto('http://localhost:3000/dashboard');
  await expect(page).toHaveTitle('Dashboard');
  
  // 3. Verify initial metrics load
  const metricsCount = await page.locator('.metric-card').count();
  expect(metricsCount).toBeGreaterThan(0);
  
  // 4. Wait for real-time update
  const firstValue = await page.locator('.metric-value').first().textContent();
  await page.waitForTimeout(1000);
  
  // 5. Verify update appeared (within 500ms threshold)
  const updatedValue = await page.locator('[aria-live="polite"]').first().textContent();
  expect(updatedValue).toBeDefined();
  
  // 6. Test keyboard navigation
  await page.keyboard.press('Tab');
  const focused = await page.evaluate(() => document.activeElement?.getAttribute('role'));
  expect(['button', 'region']).toContain(focused);
});

// Load Testing (tests/e2e/load.spec.ts)
import http from 'k6/http';
import { check } from 'k6';

export const options = {
  stages: [
    { duration: '30s', target: 20 },   // Ramp up
    { duration: '1m30s', target: 100 }, // Stay at 100
    { duration: '30s', target: 0 },    // Ramp down
  ],
};

export default function () {
  const res = http.get('http://localhost:3001/api/metrics?dashboard=123');
  check(res, {
    'status is 200': (r) => r.status === 200,
    'response time < 500ms': (r) => r.timings.duration < 500,
  });
}

// Performance Audit (via Lighthouse CI)
// Runs in CI pipeline after each deploy
```

**Test Coverage Report**:
```
Tests Executed:
â”œâ”€â”€ Unit Tests: 45 tests, all passing âœ“
â”œâ”€â”€ Integration Tests: 12 tests, all passing âœ“
â”œâ”€â”€ E2E Tests: 8 tests, all passing âœ“
â”œâ”€â”€ Load Test: 100 concurrent users handled âœ“
â””â”€â”€ Security Tests: 15 checks, all passing âœ“

Coverage: 87% (target: 80%) âœ“

Performance:
â”œâ”€â”€ Lighthouse: 94 (target: 90) âœ“
â”œâ”€â”€ LCP: 1.2s (target: 2.5s) âœ“
â”œâ”€â”€ FID: 45ms (target: 100ms) âœ“
â””â”€â”€ CLS: 0.08 (target: 0.1) âœ“

Security:
â”œâ”€â”€ Dependencies: No vulnerabilities âœ“
â”œâ”€â”€ OWASP Top 10: All passed âœ“
â””â”€â”€ API Security: All checks passed âœ“

Accessibility:
â”œâ”€â”€ WCAG 2.1 AA: All passed âœ“
â””â”€â”€ Keyboard Navigation: Working âœ“
```

### Phase 6: Quality Gate Validators

All validators run in parallel:

#### Hook: web_performance_guard.py

```python
# Lighthouse CI Results
# Homepage: 92 (target: 90) âœ“
# Dashboard: 94 (target: 90) âœ“
# Bundle size: 187KB (target: 250KB) âœ“
# Build time: 78s (target: 120s) âœ“

# Core Web Vitals
# LCP: 1.5s (target: 2.5s) âœ“
# FID: 42ms (target: 100ms) âœ“
# CLS: 0.07 (target: 0.1) âœ“
```

#### Hook: web_security_scanner.py

```python
# Security Scan Results
# Dependencies: 0 critical, 0 high âœ“
# OWASP patterns: All clear âœ“
# Secrets: None detected âœ“
# Authorization: Verified âœ“
# Rate limiting: Configured âœ“
```

#### Hook: seo_validator.py

```python
# SEO Validation Results
# Private page correctly marked: robots.index=false âœ“
# Meta tags present: title, description âœ“
# Open Graph tags: Complete âœ“
# Structured data: Valid JSON-LD âœ“
# URL structure: SEO-friendly âœ“
```

#### Hook: accessibility_validator.py

```python
# Accessibility Results
# WCAG 2.1 AA: All passed âœ“
# Keyboard navigation: Complete âœ“
# Screen reader: Compatible âœ“
# Color contrast: WCAG AA+ âœ“
# ARIA labels: Proper usage âœ“
```

#### Hook: test_enforcer.py

```python
# Test Coverage Results
# Overall: 87% (target: 80%) âœ“
# Critical paths: 100% (target: 100%) âœ“
# Branches: 82% (target: 75%) âœ“
# New code: 92% (target: 90%) âœ“
```

#### Hook: stop_validator.py (Final Gate)

```python
# Final Quality Check
# TypeScript compilation: âœ“ PASS
# ESLint: âœ“ PASS (0 errors, 0 warnings)
# Prettier: âœ“ PASS (formatting correct)
# Tests: âœ“ PASS (65/65 passing)
# Coverage: âœ“ PASS (87% > 80%)
# Performance: âœ“ PASS (Lighthouse 94)
# Security: âœ“ PASS (0 critical issues)
# Accessibility: âœ“ PASS (WCAG AA)
# SEO: âœ“ PASS (meta tags correct)

# Status: âœ“âœ“âœ“ ALL GATES PASSED âœ“âœ“âœ“
# Ready for human review and approval
```

### Phase 7: Human Review

Orchestrator presents summary:

```markdown
## Real-Time Dashboard Implementation Summary

### Execution Metrics
- Total execution time: 42 minutes
- Parallelization efficiency: 4.2X
- Number of agents: 5
- Number of files created/modified: 34

### Frontend Changes
âœ… **4 components created**
- Dashboard page (with SSR support)
- Real-time metrics widget
- Connection status indicator
- Metrics grid layout

âœ… **3 custom hooks**
- useMetricsWebSocket (handles connection lifecycle)
- useMetricsStore (state management)
- useMetricsPolling (fallback to polling)

âœ… **SEO Implementation**
- Private page correctly marked (robots.index = false)
- Meta tags added
- Open Graph tags included

âœ… **Accessibility**
- All ARIA labels present
- Keyboard navigation complete
- Screen reader compatible
- Color contrast: WCAG AAA

âœ… **Performance**
- Bundle size impact: +12KB (within budget)
- Lighthouse score: 94 (target: 90)
- LCP: 1.2s (target: 2.5s)

### Backend Changes
âœ… **3 API endpoints**
- GET /api/metrics (fetch metrics)
- POST /api/metrics/subscribe (WebSocket)
- GET /api/metrics/health (health check)

âœ… **Business Logic**
- Metrics aggregation service
- Real-time update mechanism
- Query optimization for performance

âœ… **Security**
- JWT authentication on all endpoints
- Rate limiting (100 req/min per user)
- WebSocket authentication
- Input validation and sanitization

âœ… **Testing**
- 12 integration tests (all passing)
- 100% coverage of core logic
- Load test: 100 concurrent users handled

### Infrastructure Changes
âœ… **Auto-Scaling**
- Load balancer configured
- Auto-scaling: 2-10 instances
- Health checks configured

âœ… **Monitoring**
- CloudWatch dashboard
- CPU and connection alarms
- Real-time metrics collection

### Quality Gates
âœ… All 9 quality gates passed:
1. TypeScript compilation âœ“
2. Linting (ESLint) âœ“
3. Formatting (Prettier) âœ“
4. Unit tests âœ“
5. Integration tests âœ“
6. Performance budget âœ“
7. Security scan âœ“
8. Accessibility audit âœ“
9. SEO validation âœ“

### Risk Assessment
**Low Risk**
- All code follows established patterns
- Full test coverage
- No breaking changes
- Proper error handling
- Security validated

### Recommendations
1. Review WebSocket rate limiting in production
2. Monitor WebSocket connection pool size
3. Consider implementing metrics caching

### Next Steps for Approval
1. âœ… Review generated code in GitHub PR
2. âœ… Run locally: `npm run dashboard:dev`
3. âœ… Test WebSocket updates manually
4. âœ… Approve PR or request changes
5. âœ… Merge â†’ Automatic deployment

**Code is ready for review. Awaiting human approval.**
```

### Phase 8: Human Reviews Generated Code

Developer reviews PR in GitHub:

```markdown
## PR: Implement Real-Time Dashboard

### Files Changed: 34

#### frontend/src/features/dashboard/ (9 files)
- âœ… Dashboard.tsx (main component, 45 lines)
- âœ… hooks/useMetricsWebSocket.ts (WebSocket hook, 38 lines)
- âœ… components/MetricsWidget.tsx (widget, 28 lines)
- âœ… store/dashboardSlice.ts (state, 42 lines)
- âœ… types/dashboard.types.ts (types, 18 lines)
- âœ… tests/dashboard.test.tsx (unit tests, 65 lines)
- âœ… tests/dashboard.e2e.spec.ts (E2E tests, 48 lines)
- âœ… utils/metricsFormatter.ts (utilities, 22 lines)
- âœ… README.md (documentation, 15 lines)

**Code Quality**: âœ… Excellent
- Clear naming conventions
- Proper TypeScript typing
- Accessibility attributes present
- Comprehensive error handling

**Performance**: âœ… Optimized
- Lazy loading implemented
- Memoization where appropriate
- Efficient WebSocket handling

#### backend/api/metrics/ (8 files)
- âœ… metrics.controller.ts (47 lines)
- âœ… metrics.service.ts (89 lines)
- âœ… metrics.gateway.ts (WebSocket server, 76 lines)
- âœ… metrics.dto.ts (DTOs, 24 lines)
- âœ… types/metrics.types.ts (types, 31 lines)
- âœ… tests/metrics.integration.test.ts (78 lines)
- âœ… tests/metrics.websocket.test.ts (95 lines)
- âœ… README.md (documentation, 12 lines)

**Code Quality**: âœ… Excellent
- Proper error handling
- Input validation
- Rate limiting implemented
- Security headers set

**Database**: âœ… Optimized
- Query indexed for performance
- Connection pooling configured
- Migration included

#### infra/terraform/ (6 files)
- âœ… websocket_lb.tf (load balancer, 42 lines)
- âœ… websocket_scaling.tf (auto-scaling, 58 lines)
- âœ… websocket_monitoring.tf (monitoring, 35 lines)
- âœ… variables.tf (variables, 28 lines)
- âœ… outputs.tf (outputs, 15 lines)
- âœ… deploy.sh (deployment script, 22 lines)

**Infrastructure**: âœ… Production-Ready
- High availability configured
- Proper monitoring
- Cost-optimized
- Secure by default

### Reviewer Comments

**@human-reviewer**: "Code looks great! Nice job on the WebSocket implementation.
A few observations:

1. âœ… Real-time updates < 500ms as required
2. âœ… Performance budgets met
3. âœ… Security looks solid
4. âš ï¸ Consider adding retry logic to WebSocket reconnection
5. âš ï¸ Monitor connection pool in first week

Approved! Ship it!"

### CI Pipeline Results
- âœ… All checks passing
- âœ… Build: 78s (well within budget)
- âœ… Tests: 85/85 passing
- âœ… Coverage: 87%
- âœ… Lighthouse: 94
- âœ… Security: Clean
```

### Phase 9: Approval and Merge

Developer approves:

```bash
# Merge the PR
git merge feature/dashboard

# Triggers CI/CD pipeline automatically
```

### Phase 10: Deployment Pipeline

#### CI/CD in GitHub Actions

```yaml
# .github/workflows/deploy-production.yml

name: Deploy Production

on:
  push:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-node@v3
        with:
          node-version: '18'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Run tests
        run: npm test -- --coverage
      
      - name: Run security scan
        run: npm run security:scan
  
  build:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-node@v3
      - run: npm ci
      
      - name: Build frontend
        run: npm run build:frontend
      
      - name: Build backend
        run: npm run build:backend
      
      - name: Build Docker images
        run: |
          docker build -f infra/docker/frontend.Dockerfile -t frontend:latest .
          docker build -f infra/docker/backend.Dockerfile -t backend:latest .
      
      - name: Push to registry
        run: |
          aws ecr get-login-password | docker login --username AWS --password-stdin $ECR_REGISTRY
          docker tag frontend:latest $ECR_REGISTRY/frontend:${{ github.sha }}
          docker push $ECR_REGISTRY/frontend:${{ github.sha }}
  
  deploy-staging:
    needs: build
    runs-on: ubuntu-latest
    steps:
      - name: Deploy to staging
        run: |
          terraform -chdir=infra/terraform/staging apply -auto-approve \
            -var="image_tag=${{ github.sha }}"
      
      - name: Run smoke tests
        run: npm run test:smoke -- --env=staging
  
  deploy-production:
    needs: deploy-staging
    environment: production
    runs-on: ubuntu-latest
    steps:
      - name: Deploy to production (blue-green)
        run: |
          ./infra/deploy/blue-green-deploy.sh ${{ github.sha }}
      
      - name: Health checks
        run: |
          for i in {1..10}; do
            if curl -f https://api.example.com/health; then
              echo "Health check passed"
              exit 0
            fi
            sleep 5
          done
          echo "Health checks failed"
          exit 1
      
      - name: Notify team
        run: |
          curl -X POST -H 'Content-type: application/json' \
            --data '{"text":"Real-time dashboard deployed to production"}' \
            $SLACK_WEBHOOK_URL
```

**Deployment Output**:
```
âœ… Tests passed: 85/85
âœ… Build successful: frontend + backend
âœ… Docker images pushed to ECR
âœ… Staging deployment: blue-green initiated
âœ… Smoke tests passed on staging
âœ… Production deployment: blue-green promotion
âœ… Health checks: All passing
âœ… Monitoring: Alerts configured
âœ… Team notified via Slack

Real-time Dashboard is now live in production! ðŸš€
```

## System Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       HUMAN DEVELOPER                               â”‚
â”‚  Edits product/ â†’ Submits to Claude Code â†’ Reviews PR â†’ Approves   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  user_prompt_submit.py â”‚ Validates request
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  prd_validator.py      â”‚ Ensures PRD complete
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   ORCHESTRATOR (Claude Code)            â”‚
            â”‚   â€¢ Analyzes PRD                        â”‚
            â”‚   â€¢ Creates execution plan              â”‚
            â”‚   â€¢ Delegates to agents                 â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                 â”‚                 â”‚              â”‚
        â–¼                 â–¼                 â–¼              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Frontend   â”‚  â”‚ Backend  â”‚  â”‚ Infra        â”‚  â”‚ Security     â”‚
    â”‚ Engineer   â”‚  â”‚ Engineer â”‚  â”‚ Guardian     â”‚  â”‚ Reviewer     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                â”‚               â”‚                  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Hooks fire in   â”‚
                    â”‚ parallel:       â”‚
                    â”‚ â€¢ pre_tool_use  â”‚
                    â”‚ â€¢ post_tool_use â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                â”‚                   â”‚
        â–¼                â–¼                   â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Performance  â”‚  â”‚ Security     â”‚  â”‚ SEO & A11Y   â”‚
    â”‚ Guard        â”‚  â”‚ Scanner      â”‚  â”‚ Validators   â”‚
    â”‚ â€¢ Lighthouse â”‚  â”‚ â€¢ CVEs       â”‚  â”‚ â€¢ WCAG       â”‚
    â”‚ â€¢ Bundle     â”‚  â”‚ â€¢ Patterns   â”‚  â”‚ â€¢ Meta tags  â”‚
    â”‚ â€¢ Core Vitalsâ”‚  â”‚ â€¢ Secrets    â”‚  â”‚ â€¢ Keyboard   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Test       â”‚
                    â”‚ Enforcer   â”‚ Validates coverage
                    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Stop Validator â”‚ Final gate
                    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Orchestrator Synthesis      â”‚
            â”‚ â€¢ Summary report            â”‚
            â”‚ â€¢ Ready for review          â”‚
            â”‚ â€¢ Quality metrics           â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Human Reviews PR & Approves  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                    Yes â”€â”€â”´â”€â”€ No (request changes)
                    â”‚
                    â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Merge to main branch    â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ GitHub Actions CI/CD     â”‚
            â”‚ â€¢ Test & Build           â”‚
            â”‚ â€¢ Deploy to staging      â”‚
            â”‚ â€¢ Smoke tests            â”‚
            â”‚ â€¢ Blue-green to prod     â”‚
            â”‚ â€¢ Health checks          â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ PRODUCTION LIVE          â”‚
            â”‚ Real-time dashboard      â”‚
            â”‚ served to users          â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Summary

This workflow demonstrates:

1. **Clear Separation of Concerns**: Humans define WHAT (PRD), AI determines HOW (implementation)
2. **Parallel Execution**: 5 agents work simultaneously on different layers
3. **Automated Quality**: Multiple hooks enforce standards automatically
4. **Quick Feedback**: All validation happens in minutes, not days
5. **Full Traceability**: Every change audited and version-controlled
6. **Continuous Monitoring**: Observability built-in from the start

**Total time from PRD update to production: ~1-2 hours**
**Total developer hands-on time: ~30 minutes**

This is the power of AI-orchestrated development for web applications.

---

Next: [QUICKSTART.md](./QUICKSTART.md) for practical setup instructions.
